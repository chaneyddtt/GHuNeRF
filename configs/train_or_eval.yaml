task: 'if_nerf'
gpus: [0]


train_dataset_module: 'lib.datasets.light_stage.can_smpl_bw_diffview_select'
train_dataset_path: 'lib/datasets/light_stage/can_smpl_bw_diffview_select.py'
test_dataset_module: 'lib.datasets.light_stage.can_smpl_bw_diffview_select'
test_dataset_path: 'lib/datasets/light_stage/can_smpl_bw_diffview_select.py'

network_module: 'lib.networks.latent_xyzc'
network_path: 'lib/networks/latent_xyzc.py'

cross_transformer_network_module: 'lib.networks.cross_transformer_v9'
cross_transformer_network_path: 'lib/networks/cross_transformer_v9.py'

renderer_module: 'lib.networks.renderer.if_clight_renderer_bwv3'
renderer_path: 'lib/networks/renderer/if_clight_renderer_bwv3.py'

trainer_module: 'lib.train.trainers.if_nerf_clight'
trainer_path: 'lib/train/trainers/if_nerf_clight.py'

evaluator_module: 'lib.evaluators.if_nerf'
evaluator_path: 'lib/evaluators/if_nerf.py'

visualizer_module: 'lib.visualizers.if_nerf'
visualizer_path: 'lib/visualizers/if_nerf.py'

# generalization configuration
virt_data_root: 'data/zju_mocap'
rasterize_root: 'data/zju_rasterization'
time_steps: 20
time_mult: [0,-20, 20]
use_viz_test: True
use_fg_masking: False
rasterize: True
weight: 'cross_transformer'
cross_att_mode: 'cross_att'
tem_trans: False
no_residue_cross_att: False

jitter: False
random_intv: False
test_sample_cam: True # sample camera views to evaluate
zju_313_315_sample_cam: [3, 5, 10, 12, 18, 20]
zju_sample_cam: [3, 5, 10, 12, 18, 20]
exp_folder_name: 'debug'

run_mode: 'train' # code running mode: 'train' 'test'
test_mode: 'model_x_motion_x' # 'model_o_motion_o', 'model_o_motion_x', 'model_x_motion_o', 'model_x_motion_x'

human: 392
num_alpha_res: 1
pretrained: True # encoder pretrained or not


img_feat_size: 256
embed_size: 64
save_freq: 50
save_epoch: 250

train:
    dataset: Human392_0001_Train
    batch_size: 1
    collator: ''
    lr: 5e-4
    weight_decay: 0
    epoch: 500
    scheduler:
        type: 'exponential'
        gamma: 0.1
        decay_epochs: 1000
    num_workers: 4 #4 #16

test:
    dataset: Human392_0001_Test
    sampler: 'FrameSampler'
    batch_size: 1
    collator: ''
    epoch: -1 #600  # which epoch to test

ep_iter: 500
save_ep: 1500
eval_ep: 50

# training options
netdepth: 8
netwidth: 256
netdepth_fine: 8
netwidth_fine: 256
netchunk: 65536
chunk: 32768

no_batching: True

precrop_iters: 500
precrop_frac: 0.5

# network options
point_feature: 6

# rendering options
use_viewdirs: True
i_embed: 0
xyz_res: 10
view_res: 4
raw_noise_std: 0

N_samples: 64
N_importance: 128
N_rand: 1024

near: 1
far: 3

perturb: 1
white_bkgd: False
render_views: 100

# data options
res: 256
ratio: 0.5
test_input_view: [7]
intv: 6
ni: 300
smpl: 'smpl'
vertices: 'vertices'
params: 'params'
lbs: 'lbs'

voxel_size: [0.005, 0.005, 0.005]  # dhw

# record options
log_interval: 1

# depth options:
with_depth_prior: False
depth_range: 0.05

diff_view: False

norm_th: 0.05

dist_res: 6
bw_refine: False

depth_sup: False
depth_loss_weight: 0.5

encoder:
    name: "resnet34" # ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']
    file: "unet"
    out_ch: 32

camera_embedding: False

gen_mesh: False
mesh_th: 1

pose_encode: False

same_view: False

perturb_pixel: 0.0
std: 1.0

aug_thre: 0.5
